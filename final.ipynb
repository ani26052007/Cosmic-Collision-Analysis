{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d3cde86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import miceforest as mf\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be0cb1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4034, 23) (4034,)\n",
      "(3227, 23) (3227,)\n",
      "(807, 23) (807,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "X = data.drop(columns=['hazardous'])\n",
    "Y = data['hazardous']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    Y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=Y\n",
    ")\n",
    "\n",
    "print(X.shape,Y.shape)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bc8e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_missing(data):\n",
    "    missing_counts_4 = data.isnull().sum()\n",
    "    missing_percentage_4 = (data.isnull().mean() * 100)\n",
    "\n",
    "    # Combine into a summary table for easy viewing\n",
    "    missing_summary_4 = pd.DataFrame({\n",
    "        'Missing Count': missing_counts_4,\n",
    "        'Percentage (%)': missing_percentage_4,\n",
    "        'dtype': data.dtypes\n",
    "    }).sort_values(by='Percentage (%)', ascending=False)\n",
    "\n",
    "    print(missing_summary_4)\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfbcc892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Missing Count  Percentage (%)    dtype\n",
      "orbit_uncertainity                    1261       39.076542   object\n",
      "jupiter_tisserand_invariant           1236       38.301828  float64\n",
      "epoch_osculation                      1102       34.149365  float64\n",
      "perihelion_time                       1090       33.777502  float64\n",
      "approach_month                        1090       33.777502  float64\n",
      "mean_motion                           1083       33.560583  float64\n",
      "epoch_date_close_approach              885       27.424853  float64\n",
      "semi_major_axis                        843       26.123334  float64\n",
      "perihelion_arg                         803       24.883793  float64\n",
      "asc_node_longitude                     768       23.799194  float64\n",
      "mean_anomaly                           643       19.925628  float64\n",
      "miles_per_hour                         598       18.531143  float64\n",
      "approach_year                          589       18.252247  float64\n",
      "aphelion_dist                          586       18.159281  float64\n",
      "miss_dist_astronomical                 433       13.418035  float64\n",
      "approach_day                           393       12.178494  float64\n",
      "orbital_period                         381       11.806632   object\n",
      "name                                     0        0.000000    int64\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop_ = ['miss_dist_miles', 'miss_dist_kilometers', 'miss_dist_lunar', 'relative_velocity_km_per_hr', 'relative_velocity_km_per_sec']\n",
    "X_train =  X_train.drop(columns = columns_to_drop_)\n",
    "X_test =  X_test.drop(columns = columns_to_drop_)\n",
    "\n",
    "missing_counts_1 = X_train.isnull().sum()\n",
    "missing_percentage_1 = (X_train.isnull().mean() * 100)\n",
    "\n",
    "# Combine into a summary table for easy viewing\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Count': missing_counts_1,\n",
    "    'Percentage (%)': missing_percentage_1,\n",
    "    'dtype': X_train.dtypes\n",
    "}).sort_values(by='Percentage (%)', ascending=False)\n",
    "\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f3169f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled 792 mean_motion from semi_major_axis\n",
      "Filled 552 semi_major_axis from mean_motion\n",
      "Calculated 2402 eccentricity values\n",
      "                             Missing Count  Percentage (%)    dtype\n",
      "jupiter_tisserand_invariant           1236       38.301828  float64\n",
      "epoch_osculation                      1102       34.149365  float64\n",
      "perihelion_time                       1090       33.777502  float64\n",
      "approach_month                        1090       33.777502  float64\n",
      "epoch_date_close_approach              885       27.424853  float64\n",
      "eccentricity                           825       25.565541  float64\n",
      "perihelion_arg                         803       24.883793  float64\n",
      "asc_node_longitude                     768       23.799194  float64\n",
      "mean_anomaly                           643       19.925628  float64\n",
      "miles_per_hour                         598       18.531143  float64\n",
      "approach_year                          589       18.252247  float64\n",
      "aphelion_dist                          586       18.159281  float64\n",
      "miss_dist_astronomical                 433       13.418035  float64\n",
      "approach_day                           393       12.178494  float64\n",
      "orbital_period                         381       11.806632   object\n",
      "mean_motion                            291        9.017663  float64\n",
      "semi_major_axis                        291        9.017663  float64\n",
      "name                                     0        0.000000    int64\n",
      "orbit_uncertainity                       0        0.000000   object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AU = 1.496e11\n",
    "G = 6.67430e-11\n",
    "M_SUN = 1.989e30\n",
    "MPH_to_KPS = 2236.94\n",
    "\n",
    "\n",
    "def imputations(input_df):\n",
    "    # 1. Properly copy the dataframe\n",
    "    da = input_df.copy()\n",
    "\n",
    "    # 2. Fill categorical missing values\n",
    "    da['orbit_uncertainity'] = da['orbit_uncertainity'].fillna('Unknown')\n",
    "\n",
    "    # --- Kepler's 3rd Law Imputations ---\n",
    "    \n",
    "    # Fill mean_motion\n",
    "    m1 = da['mean_motion'].isna() & da['semi_major_axis'].notna()\n",
    "    if m1.any():\n",
    "        a_m = da.loc[m1, 'semi_major_axis'] * AU\n",
    "        n_rad_per_sec = np.sqrt(G * M_SUN / a_m**3)\n",
    "        da.loc[m1, 'mean_motion'] = n_rad_per_sec * (180/np.pi) * 86400\n",
    "        print(f\"Filled {m1.sum()} mean_motion from semi_major_axis\")\n",
    "    \n",
    "    # Fill semi_major_axis\n",
    "    m2 = da['semi_major_axis'].isna() & da['mean_motion'].notna()\n",
    "    if m2.any():\n",
    "        n_rad_per_sec = da.loc[m2, 'mean_motion'] * (np.pi/180) / 86400\n",
    "        a_m = (G * M_SUN / n_rad_per_sec**2)**(1/3)\n",
    "        da.loc[m2, 'semi_major_axis'] = a_m / AU\n",
    "        print(f\"Filled {m2.sum()} semi_major_axis from mean_motion\")\n",
    "\n",
    "    # --- Eccentricity and Aphelion ---\n",
    "\n",
    "    m3 = da['aphelion_dist'].notna() & da['semi_major_axis'].notna()\n",
    "    if m3.any():\n",
    "        # Ensure column exists before calculation\n",
    "        if 'eccentricity' not in da.columns:\n",
    "            da['eccentricity'] = np.nan\n",
    "        da.loc[m3, 'eccentricity'] = (da.loc[m3, 'aphelion_dist'] / \n",
    "                                      da.loc[m3, 'semi_major_axis']) - 1\n",
    "        print(f\"Calculated {m3.sum()} eccentricity values\")\n",
    "    \n",
    "    if 'eccentricity' in da.columns:\n",
    "        m4 = (da['aphelion_dist'].isna() & \n",
    "              da['semi_major_axis'].notna() & \n",
    "              da['eccentricity'].notna())\n",
    "        if m4.any():\n",
    "            da.loc[m4, 'aphelion_dist'] = (da.loc[m4, 'semi_major_axis'] * \n",
    "                                          (1 + da.loc[m4, 'eccentricity']))\n",
    "            print(f\"Filled {m4.sum()} aphelion_dist\")\n",
    "    \n",
    "    cols_to_check = ['mean_motion', 'semi_major_axis', 'aphelion_dist', 'eccentricity']\n",
    "    \n",
    "    for col in cols_to_check:\n",
    "        if col in da.columns:\n",
    "            neg_mask = da[col] < 0\n",
    "            count = neg_mask.sum()\n",
    "            if count > 0:\n",
    "                da.loc[neg_mask, col] = np.nan\n",
    "                print(f\"Set {count} negative values to NaN in {col}\")\n",
    "\n",
    "    return da\n",
    "\n",
    "z = imputations(X_train)\n",
    "\n",
    "print_missing(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "988100a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted components from 2342 timestamps\n",
      "Created 415 timestamps from components\n",
      "                             Missing Count  Percentage (%)    dtype\n",
      "jupiter_tisserand_invariant           1236       38.301828  float64\n",
      "epoch_osculation                      1102       34.149365  float64\n",
      "perihelion_time                       1090       33.777502  float64\n",
      "eccentricity                           825       25.565541  float64\n",
      "perihelion_arg                         803       24.883793  float64\n",
      "asc_node_longitude                     768       23.799194  float64\n",
      "mean_anomaly                           643       19.925628  float64\n",
      "miles_per_hour                         598       18.531143  float64\n",
      "aphelion_dist                          586       18.159281  float64\n",
      "epoch_date_close_approach              470       14.564611  float64\n",
      "miss_dist_astronomical                 433       13.418035  float64\n",
      "orbital_period                         381       11.806632   object\n",
      "approach_month                         316        9.792377  float64\n",
      "mean_motion                            291        9.017663  float64\n",
      "semi_major_axis                        291        9.017663  float64\n",
      "approach_year                          153        4.741246  float64\n",
      "approach_day                           120        3.718624  float64\n",
      "name                                     0        0.000000    int64\n",
      "orbit_uncertainity                       0        0.000000   object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fill_temporal_features_v2(da):\n",
    "    da = da.copy()\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Strategy 1: Extract from timestamp wherever timestamp exists\n",
    "    has_ts = da['epoch_date_close_approach'].notna()\n",
    "    \n",
    "    if has_ts.sum() > 0:\n",
    "        # Convert all timestamps to datetime\n",
    "        all_dates = pd.to_datetime(da['epoch_date_close_approach'], \n",
    "                                   unit='ms', errors='coerce')\n",
    "        \n",
    "        # Fill year\n",
    "        da.loc[has_ts & da['approach_year'].isna(), 'approach_year'] = \\\n",
    "            all_dates[has_ts & da['approach_year'].isna()].dt.year\n",
    "        \n",
    "        # Fill month  \n",
    "        da.loc[has_ts & da['approach_month'].isna(), 'approach_month'] = \\\n",
    "            all_dates[has_ts & da['approach_month'].isna()].dt.month\n",
    "        \n",
    "        # Fill day\n",
    "        da.loc[has_ts & da['approach_day'].isna(), 'approach_day'] = \\\n",
    "            all_dates[has_ts & da['approach_day'].isna()].dt.day\n",
    "        \n",
    "        print(f\"Extracted components from {has_ts.sum()} timestamps\")\n",
    "    \n",
    "    # Strategy 2: Create timestamp from components\n",
    "    has_components = (da['approach_year'].notna() & \n",
    "                     da['approach_month'].notna() & \n",
    "                     da['approach_day'].notna())\n",
    "    needs_ts = da['epoch_date_close_approach'].isna() & has_components\n",
    "    \n",
    "    if needs_ts.sum() > 0:\n",
    "        # Build datetime\n",
    "        temp_df = pd.DataFrame({\n",
    "            'year': da.loc[needs_ts, 'approach_year'].astype(int),\n",
    "            'month': da.loc[needs_ts, 'approach_month'].astype(int),\n",
    "            'day': da.loc[needs_ts, 'approach_day'].astype(int)\n",
    "        })\n",
    "        \n",
    "        new_dates = pd.to_datetime(temp_df, errors='coerce')\n",
    "        da.loc[needs_ts, 'epoch_date_close_approach'] = new_dates.astype(int) / 10**6\n",
    "        \n",
    "        print(f\"Created {needs_ts.sum()} timestamps from components\")\n",
    "    \n",
    "    return da\n",
    "\n",
    "z = fill_temporal_features_v2(z)\n",
    "print_missing(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3153899a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Filled 316 approach_month values with mode: 2\n",
      "âœ“ Filled 120 approach_day values with median: 15\n",
      "âœ“ Filled 153 approach_year values with median: 2008\n",
      "âœ“ Filled 1102 epoch_osculation values with median: 2458000.50\n",
      "\n",
      "âœ… Temporal features imputation complete!\n",
      "\n",
      "Remaining missing in temporal features:\n",
      "approach_month                 0\n",
      "approach_day                   0\n",
      "approach_year                  0\n",
      "epoch_osculation               0\n",
      "epoch_date_close_approach    470\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def simple_temporal_imputation(da):\n",
    "    \"\"\"\n",
    "    Fill remaining temporal features with simple statistical imputation.\n",
    "    \n",
    "    Strategy:\n",
    "    - approach_month: mode (most common month)\n",
    "    - approach_day: median (middle of month â‰ˆ 15)\n",
    "    - approach_year: median (central tendency)\n",
    "    - epoch_osculation: median (reference date)\n",
    "    \"\"\"\n",
    "    da = da.copy()\n",
    "    \n",
    "    # Fill approach_month with mode\n",
    "    if da['approach_month'].isna().sum() > 0:\n",
    "        month_mode = da['approach_month'].mode()[0]\n",
    "        count_before = da['approach_month'].isna().sum()\n",
    "        da['approach_month'] = da['approach_month'].fillna(month_mode)\n",
    "        print(f\"âœ“ Filled {count_before} approach_month values with mode: {int(month_mode)}\")\n",
    "    \n",
    "    # Fill approach_day with median\n",
    "    if da['approach_day'].isna().sum() > 0:\n",
    "        day_median = da['approach_day'].median()\n",
    "        count_before = da['approach_day'].isna().sum()\n",
    "        da['approach_day'] = da['approach_day'].fillna(day_median)\n",
    "        print(f\"âœ“ Filled {count_before} approach_day values with median: {int(day_median)}\")\n",
    "    \n",
    "    # Fill approach_year with median\n",
    "    if da['approach_year'].isna().sum() > 0:\n",
    "        year_median = da['approach_year'].median()\n",
    "        count_before = da['approach_year'].isna().sum()\n",
    "        da['approach_year'] = da['approach_year'].fillna(year_median)\n",
    "        print(f\"âœ“ Filled {count_before} approach_year values with median: {int(year_median)}\")\n",
    "    \n",
    "    # Fill epoch_osculation with median\n",
    "    if da['epoch_osculation'].isna().sum() > 0:\n",
    "        osculation_median = da['epoch_osculation'].median()\n",
    "        count_before = da['epoch_osculation'].isna().sum()\n",
    "        da['epoch_osculation'] = da['epoch_osculation'].fillna(osculation_median)\n",
    "        print(f\"âœ“ Filled {count_before} epoch_osculation values with median: {osculation_median:.2f}\")\n",
    "    \n",
    "    print(f\"\\nâœ… Temporal features imputation complete!\")\n",
    "    \n",
    "    return da\n",
    "def sync_timestamps_final(da):\n",
    "    \"\"\"\n",
    "    Create timestamps for any remaining rows that have complete components.\n",
    "    Call this AFTER simple_temporal_imputation.\n",
    "    \"\"\"\n",
    "    da = da.copy()\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Find rows with components but missing timestamp\n",
    "    has_components = (da['approach_year'].notna() & \n",
    "                     da['approach_month'].notna() & \n",
    "                     da['approach_day'].notna())\n",
    "    needs_ts = da['epoch_date_close_approach'].isna() & has_components\n",
    "    \n",
    "    if needs_ts.sum() > 0:\n",
    "        try:\n",
    "            temp_df = pd.DataFrame({\n",
    "                'year': da.loc[needs_ts, 'approach_year'].astype(int),\n",
    "                'month': da.loc[needs_ts, 'approach_month'].astype(int),\n",
    "                'day': da.loc[needs_ts, 'approach_day'].astype(int)\n",
    "            })\n",
    "            \n",
    "            new_dates = pd.to_datetime(temp_df, errors='coerce')\n",
    "            da.loc[needs_ts, 'epoch_date_close_approach'] = new_dates.astype(int) / 10**6\n",
    "            \n",
    "            print(f\"âœ“ Created {needs_ts.sum()} timestamps from imputed components\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš  Warning: Could not create some timestamps - {e}\")\n",
    "    \n",
    "    return da\n",
    "\n",
    "# After your cross-filling\n",
    "z_v3 = simple_temporal_imputation(z)\n",
    "\n",
    "# Verify all temporal features are filled\n",
    "temporal_cols = ['approach_month', 'approach_day', 'approach_year', \n",
    "                 'epoch_osculation', 'epoch_date_close_approach']\n",
    "print(\"\\nRemaining missing in temporal features:\")\n",
    "print(z_v3[temporal_cols].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5c4441d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Created 470 timestamps from imputed components\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ FINAL TEMPORAL FEATURES STATUS\n",
      "============================================================\n",
      "epoch_date_close_approach    0\n",
      "approach_month               0\n",
      "approach_day                 0\n",
      "approach_year                0\n",
      "epoch_osculation             0\n",
      "dtype: int64\n",
      "\n",
      "âœ… Should be all zeros!\n"
     ]
    }
   ],
   "source": [
    "def fill_remaining_timestamps(da):\n",
    "    \"\"\"\n",
    "    Fill any remaining epoch_date_close_approach with median.\n",
    "    Use this as a fallback if sync_timestamps_final doesn't catch everything.\n",
    "    \"\"\"\n",
    "    da = da.copy()\n",
    "    \n",
    "    if da['epoch_date_close_approach'].isna().sum() > 0:\n",
    "        ts_median = da['epoch_date_close_approach'].median()\n",
    "        count_before = da['epoch_date_close_approach'].isna().sum()\n",
    "        da['epoch_date_close_approach'] = da['epoch_date_close_approach'].fillna(ts_median)\n",
    "        print(f\"âœ“ Filled {count_before} epoch_date_close_approach values with median: {ts_median:.2f}\")\n",
    "    \n",
    "    return da\n",
    "\n",
    "# Use it:\n",
    "z_v4 = sync_timestamps_final(z_v3)  # Try creating from components first\n",
    "z_v4 = fill_remaining_timestamps(z_v4)  # Fill any stragglers with median\n",
    "\n",
    "# Final verification\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ¯ FINAL TEMPORAL FEATURES STATUS\")\n",
    "print(\"=\"*60)\n",
    "print(z_v4[['epoch_date_close_approach', 'approach_month', \n",
    "            'approach_day', 'approach_year', 'epoch_osculation']].isna().sum())\n",
    "print(\"\\nâœ… Should be all zeros!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
